{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruslan709/nes/blob/main/Untitled21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "!cp /content/drive/MyDrive/lfw.zip .\n",
        "with zipfile.ZipFile(\"lfw.zip\") as z:\n",
        "    z.extractall()\n",
        "\n",
        "data_root = Path(\"lfw-deepfunneled/lfw-deepfunneled\")\n"
      ],
      "metadata": {
        "id": "O06YF9hMRTtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "import torchvision.models as tmodels\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "wpB6XSeNjnPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "person_to_images = defaultdict(list)\n",
        "\n",
        "for person in data_root.iterdir():\n",
        "    if person.is_dir():\n",
        "        imgs = list(person.glob(\"*.jpg\"))\n",
        "        if len(imgs) > 1:\n",
        "            person_to_images[person.name] = imgs\n",
        "\n",
        "people = list(person_to_images.keys())\n",
        "np.random.shuffle(people)\n",
        "\n",
        "test_size = int(len(people) * 0.2)\n",
        "\n",
        "test_people = people[:test_size]\n",
        "train_people = people[test_size:]\n"
      ],
      "metadata": {
        "id": "9fD5a2XjVhD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tf = T.Compose([\n",
        "    T.RandomResizedCrop(112, scale=(0.6, 1.0)),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.RandomRotation(10),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n",
        "\n",
        "test_tf = T.Compose([\n",
        "    T.Resize((112,112)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.5]*3, [0.5]*3)\n",
        "])\n"
      ],
      "metadata": {
        "id": "3pgh3iRCkNF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LFWDataset(Dataset):\n",
        "    def __init__(self, people, mapping, transform):\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "        for idx, person in enumerate(people):\n",
        "            for img in mapping[person]:\n",
        "                self.samples.append((img, idx))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        path, label = self.samples[i]\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        img = self.transform(img)\n",
        "        return img, label\n",
        "\n",
        "\n",
        "train_dataset = LFWDataset(train_people, person_to_images, train_tf)\n",
        "test_dataset  = LFWDataset(test_people,  person_to_images, test_tf)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "zSkFC9lQjtmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ArcMarginProduct(nn.Module):\n",
        "    def __init__(self, in_features, out_features, s=64.0, m=0.30):\n",
        "        super().__init__()\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.weight = nn.Parameter(torch.randn(out_features, in_features))\n",
        "        nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "    def forward(self, embeddings, labels):\n",
        "        cosine = F.linear(\n",
        "            F.normalize(embeddings),\n",
        "            F.normalize(self.weight)\n",
        "        )\n",
        "        theta = torch.acos(torch.clamp(cosine, -1+1e-7, 1-1e-7))\n",
        "        phi = torch.cos(theta + self.m)\n",
        "\n",
        "        one_hot = torch.zeros_like(cosine)\n",
        "        one_hot.scatter_(1, labels.unsqueeze(1), 1)\n",
        "\n",
        "        logits = one_hot * phi + (1 - one_hot) * cosine\n",
        "        logits *= self.s\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "MwoozcmKj1kT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ArcFaceNet(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        backbone = tmodels.resnet50(weights=\"IMAGENET1K_V2\")\n",
        "        backbone.fc = nn.Identity()\n",
        "        self.backbone = backbone\n",
        "        self.embedding = nn.Linear(2048, 512)\n",
        "        self.arc = ArcMarginProduct(512, n_classes)\n",
        "\n",
        "    def forward(self, x, labels=None):\n",
        "        feat = self.backbone(x)\n",
        "        emb = F.normalize(self.embedding(feat))\n",
        "        if labels is not None:\n",
        "            logits = self.arc(emb, labels)\n",
        "            return logits, emb\n",
        "        return emb\n"
      ],
      "metadata": {
        "id": "MgnpJANNVIt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "model = ArcFaceNet(len(train_people)).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "EPOCHS = 20\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        logits, emb = model(imgs, labels)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} Loss={total_loss/len(train_loader):.4f}\")\n",
        "    scheduler.step()\n"
      ],
      "metadata": {
        "id": "xyWDawh4VKRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_embs = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        emb = model(imgs)\n",
        "        test_embs.append(emb.cpu())\n",
        "        test_labels.append(labels)\n",
        "\n",
        "test_embs = torch.cat(test_embs)\n",
        "test_labels = torch.cat(test_labels)\n",
        "\n",
        "sims = cosine_similarity(test_embs)\n",
        "np.fill_diagonal(sims, -1)\n",
        "\n",
        "top2 = sims.argsort(axis=1)[:, -1]\n",
        "pred = [test_labels[i] == test_labels[top2[i]] for i in range(len(test_labels))]\n",
        "\n",
        "accuracy = np.mean(pred)\n",
        "errors = 1 - accuracy\n",
        "\n",
        "print(f\"Всего эмбеддингов: {len(test_embs)}\")\n",
        "print(f\"Ошибок: {errors*100:.2f}%\")\n",
        "print(f\"Точность: {accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "wxZXZe7HVOMj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}